{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c87c4a8f-92e0-4953-85cc-c36ec2fd86a5",
   "metadata": {},
   "source": [
    "## Retrieval \n",
    "\n",
    "Get the relevant data from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074af4a-c9b1-4bf1-a37d-57c66a180282",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain langchain-deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23231273-5da1-4130-a647-2d8f52558fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c550cd00-f9b2-4ad6-9c9b-7a9147323e65",
   "metadata": {},
   "source": [
    "## Part 1 Overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bd01bc-7f1c-4e0a-a7bd-7fba2251b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 \n",
    "from langchain import hub \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import Chroma, InMemoryVectorStore\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain_core.runnables import RunnablePassthrough \n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langgraph.graph import START, StateGraph\n",
    "import os\n",
    "from typing_extensions import List, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb9999-4589-4651-ab2c-76ad415d42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def _set_env(var:str) :\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}\")\n",
    "_set_env(\"DEEPSEEK_API_KEY\")\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"pr-weary-bull-48\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6766761-cf4a-4810-8210-b5e1ead40cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98fb48-e0d0-410a-ac73-f0bcd5896585",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb806dc9-0274-42b4-b4ed-5610b326f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing \n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "assert len(docs) == 1\n",
    "\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269e6d5-5a13-4b71-990d-6a68ce34128a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee82483-7b77-44ea-92a9-785ec9f959bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing \n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "assert len(docs) == 1\n",
    "# print(f\"Total characters: {len(docs[0].page_content)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc572d-9b57-418b-a7f3-eb47a60794c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Analsys \n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "\n",
    "for i , document in enumerate (all_splits):\n",
    "    if i<third :\n",
    "        document.metadata[\"section\"] = \"begining\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449601b2-487a-459f-8b1d-6d9fb04fc11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5fc201-9a30-47ce-959c-b3a5cca565c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Index Chunks \n",
    "\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512986f-930d-4d02-9408-9802e3dfd8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search using Query \n",
    "from typing import Literal \n",
    "\n",
    "from typing_extensions import Annotated \n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search Query\"\"\"\n",
    "    query: Annotated[str, ..., \"Search Query to run.\"]\n",
    "    section: Annotated[\n",
    "    Literal [\"beginning\", \"middle\", \"end\"],\n",
    "    ...,\n",
    "    \"Section to Query,\",\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514edb0-dcdc-4c6f-8872-d3a07b9d5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_message = prompt.invoke({\n",
    "    \"context\" : \"this is sai\", \n",
    "    \"question\" : \"who are you?\"\n",
    "}).to_messages()\n",
    "\n",
    "print(f\"{example_message[0].content}\")\n",
    "# llm = ChatDeepSeek(\n",
    "#     model=\"deepseek-chat\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "# )\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "example_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898d858-12eb-4e86-a0f7-30690bccf2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom RAG Prompt\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template=\"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three to five sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "example_message = custom_rag_prompt.invoke({\n",
    "    \"context\" : \"this is sai\", \n",
    "    \"question\" : \"who are you?\"\n",
    "}).to_messages()\n",
    "example_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfa29b-dcf8-4c5e-8f7a-f56b4d04e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define State for application \n",
    "class State (TypedDict):\n",
    "    question:str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps \n",
    "def retrieve_old(state:State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def retrieve(state:State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter = lambda doc:doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\" :retrieved_docs }\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    strutured_llm = llm.with_structured_output(Search)\n",
    "    query = strutured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "def generate(state:State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    msgs = custom_rag_prompt.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": docs_content\n",
    "    })\n",
    "\n",
    "    response = llm.invoke(msgs)\n",
    "    return {\"answer\": response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19911919-682c-4982-bd3c-2c011143fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile application  and test \n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph=graph_builder.compile()\n",
    "\n",
    "response = graph.invoke({\n",
    "    \"question\": \"What is Reward Hacking and it's examples?\"\n",
    "})\n",
    "\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c87bb-c189-4a6f-acaa-ddcef0a09200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f3e83-29a1-4cbb-8151-73aa5567b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream steps \n",
    "\n",
    "for step in graph.stream({\"question\": \"Reward Hacking\"}, stream_mode=\"updates\"):\n",
    "    print(f\"{step}\\n\\n---------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b39d3-f82d-4601-8c8f-b7044c23d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Async Invokations \n",
    "\n",
    "response =await  graph.ainvoke({\n",
    "    \"question\":\"Reward Hacking\"\n",
    "})\n",
    "\n",
    "print(f\"{response[\"answer\"]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965febb-77ed-446f-8ce9-77a376f02d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async  stream message\n",
    "async for step in graph.astream({\"question\" :\"Reward Hacking\"}, stream_mode=\"updates\"):\n",
    "    print(f\"{step}\\n\\n--------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca90a52f-79ab-416a-bcf2-ed0113c268d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async stream tokens\n",
    "async for message, metadata in graph.astream({\"question\" :\"Reward Hacking?\"}, stream_mode=\"messages\"):\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b6411-59d0-4b4b-bada-2b8fc9a2a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d199cef-459e-4be5-a0f5-ee2e12b6b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\n",
    "    \"question\": \"What is does end of section says about Reward Hacking and it's examples?\"\n",
    "})\n",
    "print(f'Context: {response[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {response[\"answer\"]}')\n",
    "\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\n",
    "        \"question\": \"What is does end of section says about Reward Hacking and it's examples?\"\n",
    "    }, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n ----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9392a152-4539-4451-a709-f83e1a3cbd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream tokens \n",
    "\n",
    "for message, metadata in graph.stream(\n",
    "    {\n",
    "        \"question\" : \"Reward Hacking\"\n",
    "    },\n",
    "    stream_mode =\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125a5a3e-8858-4090-9ed2-ad6850887b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\n",
    "    \"question\": \"Reward Hacking examples?\"\n",
    "})\n",
    "print(f'Context: {response[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {response[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e1b13-214b-4bf2-bcad-7dc0500948eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
